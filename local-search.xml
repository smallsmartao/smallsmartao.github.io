<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>PROGRESSIVE VOICE TRIGGER DETECTION Latency Control for Keyword Spotting</title>
    <link href="/2022/06/30/kws-0630/"/>
    <url>/2022/06/30/kws-0630/</url>
    
    <content type="html"><![CDATA[<p>作者: Christin Jose, Joseph Wang, Grant P. Strimel, Mohammad Omar Khursheed, Yuriy Mishchenko,<br>Brian Kulis<br>机构: Amazon Science, United States<br>关键词: kws,max-pooling<br>链接:  <a href="https://arxiv.org/pdf/2206.07261.pdf">https://arxiv.org/pdf/2206.07261.pdf</a>       </p><h3 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h3><p>maxpooling不需要用对齐模型生成label，但是会导致额外的延迟，因为模型会倾向于多看一点下文再判断，而有时候我们需要灵活的控制延迟，像celoss我们就可以移动label来控制。</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>原始的maxpooling loss 对于正样例选取正类别后验最高的一帧算loss，对于负样例则选取负类别后验最低的一帧算loss<br><img src="https://s2.loli.net/2022/06/30/F3aUJjMI4uRzBkm.png" alt="maxpooling.png"><br>本文在选取正样例的位置的时候加了一个前移的随机量，这个量服从伯努利分布，通过控制分布中为1的概率参数，来控制前移的幅度。<br><img src="https://s2.loli.net/2022/06/30/Nf8Hl96Ja4wgztE.png" alt="maxpooling2.png"></p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h4><p>cnn网络，64维 Mel-filterbank energy (LFBE) features<br><img src="https://s2.loli.net/2022/06/30/Xv6K58AUHR3CGak.png" alt="cnn.png"></p><h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><p>准确度上b越大效果越差，0.1,0.2下和celoss性能相当<br><img src="https://s2.loli.net/2022/06/30/LkxMH2tpiXzvQ6c.png" alt="res1.png"><br>对时延的影响也符合预期<br><img src="https://s2.loli.net/2022/06/30/McBSfbCE1x8kaZ5.png" alt="res2.png"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>复现简单，解决实际问题。</p>]]></content>
    
    
    <categories>
      
      <category>论文解读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>kws</tag>
      
      <tag>maxpooling</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pruned RNN-T for fast, memory-efficient ASR training</title>
    <link href="/2022/06/30/puned-rnnt/"/>
    <url>/2022/06/30/puned-rnnt/</url>
    
    <content type="html"><![CDATA[<p>作者:  Fangjun Kuang, Liyong Guo, Wei Kang,Long Lin, Mingshuang Luo, Zengwei Yao, Daniel Povey Xiaomi<br>机构:  Xiaomi Corp., Beijing, China<br>关键词: RNN-T, memory-efficient<br>链接:  <a href="https://arxiv.org/abs/2206.13236">https://arxiv.org/abs/2206.13236</a></p><h3 id="动机">动机</h3><p>RNN-T 输出一个四维的矩阵(N,T,U,V)，N为batch size，T为时间，U为序列长度，V为词典大小，V很大的情况下，训练显存占用太大了，之前有很多减少显存占用的工作，比如去除padding，在logits上计算梯度，本文提出一种方法，用S取代U，S&lt;&lt;U，从而降低内存占用。</p><h3 id="背景">背景</h3><p>rnn-t三个部分：encoder，predictor，joint network</p><ul><li>encdoer输出(T,E)维度的矩阵，E为encoder输出维度。</li><li>predictor基于之前的非blank标签预测下一个token的分布，输出(U+1,D)维度的矩阵</li><li>joiner 组合两边的输出得到(T,U+1,V)其中L[t,u,v]代表token v在t时刻出现given y[0…u]<br>rnn-t的解码图如下：<br><img src="https://s2.loli.net/2022/06/30/4IlWAgayPXZqc3J.png" alt="decode graph"><br>我们用y代表离开这个node的概率，blank代表水平移动的概率<br><img src="https://s2.loli.net/2022/06/30/or47tnRgGOkYZSA.png" alt><br>α(t,u)代表看到x[0…t]输出y[0…u]的log输出，推理过程如下：<br><img src="https://s2.loli.net/2022/06/30/Bb5gYoLpvxc1eWH.png" alt><br>包括上一个t从u水平过来和从上一个token跳过来<br><img src="https://s2.loli.net/2022/06/30/bFtRO1g7Quz8r4X.png" alt="image.png"><br>最终RNN-T的输出是(NTUV)和ctc和aed模型的(NTV)/(NUV)他的消耗大得多。<br><img src="https://s2.loli.net/2022/06/30/hvYzo78GLUNkrQK.png" alt="image.png"><br>而实际上大部分梯度接近0，中间部分的梯度比较明显，可以看到训练后模型梯度非常集中，有点类似对齐的感觉。</li></ul><h3 id="方法">方法</h3><h4 id="Trivial-joiner-network">Trivial joiner network</h4><p>避免引入一个很大线性层<br><img src="https://s2.loli.net/2022/06/30/cKFPTlHtoWOZwyq.png" alt="image.png"></p><h4 id="Pruning-bounds">Pruning bounds</h4><p>引入常量S，只在S范围内计算loss，S之外的部分置为负无穷。这就需要我们找到一个S的边界，使得这个边界内的后验是最大的，本文提出一种估计方法，来估计S的起始位置。<br>设S=4，起始为2，那么估计为<br><img src="https://s2.loli.net/2022/06/30/bGyI5fmTt762EBq.png" alt="image.png"><br>我们需要找到其中最大的起始位置：<br><img src="https://s2.loli.net/2022/06/30/HegPh1UVbO72E6Q.png" alt="image.png"><br>孤立着看很难理解，但是如果连续看T就能理解了。<br>为了裁剪的合理，进一步约束了起始点的位置，不能倒退，不能一步超过S。<br><img src="https://s2.loli.net/2022/06/30/DCIU6Ac4ouvWwHj.png" alt="image.png"></p><h4 id="损失函数">损失函数</h4><p><img src="https://s2.loli.net/2022/06/30/YoK7lCyx1PzhdVL.png" alt="image.png"><br><img src="https://s2.loli.net/2022/06/30/cqprab2XtOSzHNo.png" alt="image.png"><br><img src="https://s2.loli.net/2022/06/30/G9TIZL2eXHjvScE.png" alt="image.png"></p><h3 id="实验">实验</h3><h4 id="实验结果">实验结果</h4><p>比较了性能和训练效率两个方面。<br><img src="https://s2.loli.net/2022/06/30/wg7Z3etybuCPlin.png" alt="image.png"><br><img src="https://s2.loli.net/2022/06/30/exbscahmIDEiRwT.png" alt="image.png"><br><img src="https://s2.loli.net/2022/06/30/HFul9zKdeqQjWN1.png" alt="image.png"></p>]]></content>
    
    
    <categories>
      
      <category>论文解读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>asr</tag>
      
      <tag>rnn-t</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Improving CTC-based ASR Models with Gated Interlayer Collaboration</title>
    <link href="/2022/06/30/ctc-0630/"/>
    <url>/2022/06/30/ctc-0630/</url>
    
    <content type="html"><![CDATA[<p>作者：Yuting Yang, Yuke Li, Binbin Du<br>机构：网易<br>关键词：CTC、流式、文本融合           </p><h3 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h3><p>ctc的独立性假设不合理，无法在模型前向中利用到文本信息</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>encoder使用conformer<br>提出一种融合方法gated interlayer collaboration （GIC）<br>首先将隐状态过一个线性层映射到字典维度得到后验，之后过embedding得到textual feature     </p><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1653620245806/9-pCZOsHA.png"></p><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1653620256457/qabF0GuNs.png"></p><p>通过门控的方式融合两个模态</p><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1653620298741/K8ecK9ker.png"></p><p>最终loss是原本的ctcloss加上所有的中间CTC的平均值</p><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1653620353727/4jlpuJez_.png"></p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h4><ul><li>实验数据<br>aishell-1 数据堂</li></ul><h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1653627039503/eTfIiAjja.png"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>其实跟<br><a href="https://arxiv.org/pdf/2104.02724.pdf">Relaxing the Conditional Independence Assumption of CTC-based ASR<br>by Conditioning on Intermediate Predictions</a><br>相比就是加了一个embedding和加权相加</p>]]></content>
    
    
    <categories>
      
      <category>论文解读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ctc</tag>
      
      <tag>asr</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
